{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from keras.layers import BatchNormalization\n",
    "from skimage import img_as_uint\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.models import *\n",
    "from keras.callbacks import *\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FCN_model(pretrained_weights = None, input_size = (None,None,3)):\n",
    "    inputs = Input(shape=input_size)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=1, strides=1)(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Fully connected layer 2\n",
    "    x = Conv2D(filters=32, kernel_size=1, strides=1)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=16, kernel_size=1, strides=1)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=8, kernel_size=1, strides=1)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    predictions = Activation('softmax')(x)\n",
    "\n",
    "    model = Model(inputs, predictions)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (None,None,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    up5 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop4))\n",
    "    merge5 = concatenate([drop3,up5], axis = 3)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = concatenate([conv2,up6], axis = 3)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv1,up7], axis = 3)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    conv8 = Conv2D(1, 1, activation = 'sigmoid')(conv7)\n",
    "    model = Model(inputs, conv8)\n",
    "    model.compile(optimizer=Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def adjustData(img,mask):\n",
    "    img = img / 255\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "\n",
    "    return (img,mask)\n",
    "\n",
    "def testGenerator(train_path):\n",
    "    for i in range(1, 15):\n",
    "        img = io.imread(os.path.join(train_path,\"%d.jpg\"%i),as_gray = True)\n",
    "        img /= 255.0 -0.5\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        img = np.reshape(img,img.shape+(1,))\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "def geneTrainNpy(image_path,mask_path):\n",
    "    image_files = [f for f in listdir(image_path) if isfile(join(image_path, f))]\n",
    "    mask_files = [f for f in listdir(mask_path) if isfile(join(mask_path, f))]\n",
    "    image_arr = []\n",
    "    mask_arr = []\n",
    "    for i in range(len(image_files)):\n",
    "        img = io.imread(os.path.join(image_path, image_files[i]))\n",
    "        mask = io.imread(os.path.join(mask_path, mask_files[i]))\n",
    "        img = np.reshape(img,img.shape)\n",
    "        mask = np.reshape(mask,mask.shape)\n",
    "        img,mask = adjustData(img,mask)\n",
    "        image_arr.append(img)\n",
    "        mask_arr.append(mask)\n",
    "    image_arr = np.array(image_arr)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "    return image_arr, mask_arr\n",
    "\n",
    "def saveResult(save_path, npyfile):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        plt.imshow(item, interpolation='nearest')\n",
    "        plt.show()\n",
    "        item /= 255. - 0.5\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.tif\"%i),img_as_uint(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model_checkpoint = ModelCheckpoint('unet_eye.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "    model = FCN_model()\n",
    "    imgs_train,imgs_mask_train = geneTrainNpy(\"eye\",\"vessels\")\n",
    "    batch_size = 2\n",
    "    epochs = 1\n",
    "    steps_per_epoch = len(imgs_train) // batch_size\n",
    "    model.fit(imgs_train,imgs_mask_train, batch_size=batch_size,\n",
    "                  epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                  verbose=1,validation_split=0.2, shuffle=True,\n",
    "                  callbacks=[model_checkpoint])\n",
    "\n",
    "\n",
    "def test_model():\n",
    "    model = unet(\"unet_eye.hdf5\")\n",
    "    testGene = testGenerator(\"eye\")\n",
    "    results = model.predict(testGene, size = 15,verbose=1)\n",
    "    saveResult(\"results\",results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train_model()\n",
    "#test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_24), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_24/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_24/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_25), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_25/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_25/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_26/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_26/beta:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_27/gamma:0' shape=(8,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_27/beta:0' shape=(8,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n\n    ValueError: `logits` and `labels` must have the same shape, received ((2, 8) vs (2, 2336, 3504)).\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [66]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [64]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      7\u001B[0m steps_per_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(imgs_train) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size\n\u001B[1;32m----> 8\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgs_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimgs_mask_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m              \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m              \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m              \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mmodel_checkpoint\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\kkopc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1189\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1182\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1183\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1184\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1185\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1186\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1187\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1188\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1189\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1190\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1191\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mc:\\users\\kkopc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mc:\\users\\kkopc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n\n    ValueError: `logits` and `labels` must have the same shape, received ((2, 8) vs (2, 2336, 3504)).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}