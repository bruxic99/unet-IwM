{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers.optimizer_v2.adam import Adam\n",
    "from skimage import img_as_uint\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from keras.metrics import Recall, Precision, Accuracy\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def unet(input_shape = (512, 512, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    chanels = 64\n",
    "    s1, p1 = encoder_block(inputs, chanels)\n",
    "    s2, p2 = encoder_block(p1, chanels*2)\n",
    "    s3, p3 = encoder_block(p2, chanels*4)\n",
    "    s4, p4 = encoder_block(p3, chanels*8)\n",
    "\n",
    "    b1 = conv_block(p4, chanels*16)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, chanels*8)\n",
    "    d2 = decoder_block(d1, s3, chanels*4)\n",
    "    d3 = decoder_block(d2, s2, chanels*2)\n",
    "    d4 = decoder_block(d3, s1, chanels)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = [Recall(), Precision()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def adjustData(img,mask, img_v, mask_v):\n",
    "    img = img / 255.\n",
    "    img = img.astype(np.float32)\n",
    "    img_v = img_v / 255.\n",
    "    img_v = img_v.astype(np.float32)\n",
    "    mask = mask /255.\n",
    "    mask = mask.astype(np.float32)\n",
    "    #mask = np.expand_dims(mask, axis=-1)\n",
    "    mask_v = mask_v /255.\n",
    "    mask_v = mask_v.astype(np.float32)\n",
    "    #mask_v = np.expand_dims(mask_v, axis=-1)\n",
    "\n",
    "    return img,mask, img_v, mask_v\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = trans.resize(x,(512,512))\n",
    "    ori_x = x\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.int32)\n",
    "    return ori_x, x\n",
    "\n",
    "def testGenerator(train_path, target_size=(512,512)):\n",
    "    for i in range(1, 19):\n",
    "        if i<10:\n",
    "            img = io.imread(os.path.join(train_path,\"0%d_h.jpg\"%i))\n",
    "        else:\n",
    "            img = io.imread(os.path.join(train_path,\"%d_h.jpg\"%i))\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (512,512),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset='training',\n",
    "        seed=seed)\n",
    "    image_valid = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset='validation',\n",
    "        seed=seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset='training',\n",
    "        seed=seed\n",
    "    )\n",
    "    mask_valid = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset='validation',\n",
    "        seed=seed\n",
    "    )\n",
    "    train_generator = zip(image_generator, mask_generator, image_valid, mask_valid)\n",
    "    for (img,mask, img_v, mask_v) in train_generator:\n",
    "        img,mask, img_v, mask_v = adjustData(img,mask, img_v, mask_v)\n",
    "        yield img,mask, img_v, mask_v\n",
    "\n",
    "def saveResult(save_path, npyfile):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        item[item > 0.3] = 1.0\n",
    "        item[item<= 0.3] = 0.0\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img_as_uint(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    validation_split = 0.3,\n",
    "                    fill_mode='nearest')\n",
    "    batch_size = 4\n",
    "    myGene = trainGenerator(4,'./','eye','mask',data_gen_args,save_to_dir = None)\n",
    "    model_checkpoint = ModelCheckpoint('unet_eye4.hdf5', verbose=1, monitor='loss', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=15, restore_best_weights=True)\n",
    "    model = unet()\n",
    "    model.load_weights('unet_eye4.hdf5')\n",
    "    x, y, x_v, y_v = next(myGene)\n",
    "    history = model.fit(x, y, steps_per_epoch=7, epochs=200, validation_data=(x_v, y_v), callbacks=[model_checkpoint, es])\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./plots/{batch_size}.png\")\n",
    "\n",
    "\n",
    "def test_model():\n",
    "    model = unet()\n",
    "    model.load_weights('unet_eye4.hdf5')\n",
    "    testGene = testGenerator(\"eye\")\n",
    "    results = model.predict(testGene, steps=18,verbose=1)\n",
    "    saveResult(\"results\",results)\n",
    "    train_y = sorted(glob(os.path.join(\"./\", \"mask\", \"*.tif\")))\n",
    "    SCORE = []\n",
    "    for i,item in enumerate(results):\n",
    "        item = item > 0.5\n",
    "        item = item.astype(np.int32)\n",
    "        item = np.squeeze(item, axis=-1)\n",
    "        y = read_mask(train_y[i])[1].flatten()\n",
    "        item = item.flatten()\n",
    "\n",
    "        acc_value = accuracy_score(y, item)\n",
    "        recall_value = recall_score(y, item, labels=[0, 1], average=\"binary\", zero_division=1)\n",
    "        precision_value = precision_score(y, item, labels=[0, 1], average=\"binary\", zero_division=1)\n",
    "        SCORE.append([acc_value, recall_value, precision_value])\n",
    "    score = np.mean(SCORE, axis=0)\n",
    "    print(f\"\\nAccuracy: {score[0]}\")\n",
    "    print(f\"Recall: {score[1]}\")\n",
    "    print(f\"Precision: {score[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamil/unet-IwM/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "Found 13 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1612 - recall_10: 0.4253 - precision_10: 0.9411\n",
      "Epoch 1: loss improved from inf to 0.16117, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.1612 - recall_10: 0.4253 - precision_10: 0.9411 - val_loss: 0.3167 - val_recall_10: 0.0116 - val_precision_10: 0.6114\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1407 - recall_10: 0.4516 - precision_10: 0.9802\n",
      "Epoch 2: loss improved from 0.16117 to 0.14072, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.1407 - recall_10: 0.4516 - precision_10: 0.9802 - val_loss: 0.3168 - val_recall_10: 0.0271 - val_precision_10: 0.6860\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1334 - recall_10: 0.4909 - precision_10: 0.9793\n",
      "Epoch 3: loss improved from 0.14072 to 0.13335, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1334 - recall_10: 0.4909 - precision_10: 0.9793 - val_loss: 0.3111 - val_recall_10: 0.0774 - val_precision_10: 0.6579\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1213 - recall_10: 0.5211 - precision_10: 0.9899\n",
      "Epoch 4: loss improved from 0.13335 to 0.12126, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1213 - recall_10: 0.5211 - precision_10: 0.9899 - val_loss: 0.2948 - val_recall_10: 0.0928 - val_precision_10: 0.8258\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1181 - recall_10: 0.5156 - precision_10: 0.9945\n",
      "Epoch 5: loss improved from 0.12126 to 0.11809, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1181 - recall_10: 0.5156 - precision_10: 0.9945 - val_loss: 0.3029 - val_recall_10: 0.0881 - val_precision_10: 0.8075\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1108 - recall_10: 0.5521 - precision_10: 0.9977\n",
      "Epoch 6: loss improved from 0.11809 to 0.11081, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1108 - recall_10: 0.5521 - precision_10: 0.9977 - val_loss: 0.3045 - val_recall_10: 0.0983 - val_precision_10: 0.7553\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1129 - recall_10: 0.5304 - precision_10: 0.9964\n",
      "Epoch 7: loss did not improve from 0.11081\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.1129 - recall_10: 0.5304 - precision_10: 0.9964 - val_loss: 0.3143 - val_recall_10: 0.0941 - val_precision_10: 0.6489\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1101 - recall_10: 0.5456 - precision_10: 0.9967\n",
      "Epoch 8: loss improved from 0.11081 to 0.11007, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1101 - recall_10: 0.5456 - precision_10: 0.9967 - val_loss: 0.2835 - val_recall_10: 0.1018 - val_precision_10: 0.9416\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1087 - recall_10: 0.5390 - precision_10: 0.9980\n",
      "Epoch 9: loss improved from 0.11007 to 0.10868, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1087 - recall_10: 0.5390 - precision_10: 0.9980 - val_loss: 0.2878 - val_recall_10: 0.1095 - val_precision_10: 0.9305\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1049 - recall_10: 0.5405 - precision_10: 0.9982\n",
      "Epoch 10: loss improved from 0.10868 to 0.10486, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.1049 - recall_10: 0.5405 - precision_10: 0.9982 - val_loss: 0.2950 - val_recall_10: 0.1135 - val_precision_10: 0.9094\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1061 - recall_10: 0.5434 - precision_10: 0.9980\n",
      "Epoch 11: loss did not improve from 0.10486\n",
      "7/7 [==============================] - 58s 9s/step - loss: 0.1061 - recall_10: 0.5434 - precision_10: 0.9980 - val_loss: 0.2893 - val_recall_10: 0.1304 - val_precision_10: 0.9344\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1026 - recall_10: 0.5552 - precision_10: 0.9993\n",
      "Epoch 12: loss improved from 0.10486 to 0.10265, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.1026 - recall_10: 0.5552 - precision_10: 0.9993 - val_loss: 0.2964 - val_recall_10: 0.1265 - val_precision_10: 0.9240\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1013 - recall_10: 0.5558 - precision_10: 0.9993\n",
      "Epoch 13: loss improved from 0.10265 to 0.10135, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.1013 - recall_10: 0.5558 - precision_10: 0.9993 - val_loss: 0.2892 - val_recall_10: 0.1362 - val_precision_10: 0.9447\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0993 - recall_10: 0.5490 - precision_10: 0.9995\n",
      "Epoch 14: loss improved from 0.10135 to 0.09930, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0993 - recall_10: 0.5490 - precision_10: 0.9995 - val_loss: 0.2832 - val_recall_10: 0.1465 - val_precision_10: 0.9602\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0968 - recall_10: 0.5719 - precision_10: 0.9998\n",
      "Epoch 15: loss improved from 0.09930 to 0.09684, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0968 - recall_10: 0.5719 - precision_10: 0.9998 - val_loss: 0.2872 - val_recall_10: 0.1488 - val_precision_10: 0.9549\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0964 - recall_10: 0.5523 - precision_10: 0.9998\n",
      "Epoch 16: loss improved from 0.09684 to 0.09643, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0964 - recall_10: 0.5523 - precision_10: 0.9998 - val_loss: 0.2843 - val_recall_10: 0.1564 - val_precision_10: 0.9561\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0956 - recall_10: 0.5608 - precision_10: 0.9999\n",
      "Epoch 17: loss improved from 0.09643 to 0.09555, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0956 - recall_10: 0.5608 - precision_10: 0.9999 - val_loss: 0.2828 - val_recall_10: 0.1716 - val_precision_10: 0.9479\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0942 - recall_10: 0.5588 - precision_10: 0.9999\n",
      "Epoch 18: loss improved from 0.09555 to 0.09418, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0942 - recall_10: 0.5588 - precision_10: 0.9999 - val_loss: 0.2658 - val_recall_10: 0.1849 - val_precision_10: 0.9568\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0934 - recall_10: 0.5636 - precision_10: 1.0000\n",
      "Epoch 19: loss improved from 0.09418 to 0.09336, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0934 - recall_10: 0.5636 - precision_10: 1.0000 - val_loss: 0.2686 - val_recall_10: 0.1901 - val_precision_10: 0.9562\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0915 - recall_10: 0.5640 - precision_10: 0.9999\n",
      "Epoch 20: loss improved from 0.09336 to 0.09150, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 105s 16s/step - loss: 0.0915 - recall_10: 0.5640 - precision_10: 0.9999 - val_loss: 0.2678 - val_recall_10: 0.1967 - val_precision_10: 0.9582\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0915 - recall_10: 0.5651 - precision_10: 1.0000\n",
      "Epoch 21: loss improved from 0.09150 to 0.09147, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 58s 9s/step - loss: 0.0915 - recall_10: 0.5651 - precision_10: 1.0000 - val_loss: 0.2639 - val_recall_10: 0.2038 - val_precision_10: 0.9673\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0895 - recall_10: 0.5661 - precision_10: 1.0000\n",
      "Epoch 22: loss improved from 0.09147 to 0.08951, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0895 - recall_10: 0.5661 - precision_10: 1.0000 - val_loss: 0.2647 - val_recall_10: 0.2122 - val_precision_10: 0.9631\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0901 - recall_10: 0.5641 - precision_10: 1.0000\n",
      "Epoch 23: loss did not improve from 0.08951\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0901 - recall_10: 0.5641 - precision_10: 1.0000 - val_loss: 0.2470 - val_recall_10: 0.2217 - val_precision_10: 0.9699\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0882 - recall_10: 0.5641 - precision_10: 1.0000\n",
      "Epoch 24: loss improved from 0.08951 to 0.08820, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0882 - recall_10: 0.5641 - precision_10: 1.0000 - val_loss: 0.2517 - val_recall_10: 0.2268 - val_precision_10: 0.9680\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0884 - recall_10: 0.5700 - precision_10: 0.9999\n",
      "Epoch 25: loss did not improve from 0.08820\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.0884 - recall_10: 0.5700 - precision_10: 0.9999 - val_loss: 0.2472 - val_recall_10: 0.2380 - val_precision_10: 0.9551\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0877 - recall_10: 0.5626 - precision_10: 1.0000\n",
      "Epoch 26: loss improved from 0.08820 to 0.08765, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0877 - recall_10: 0.5626 - precision_10: 1.0000 - val_loss: 0.2504 - val_recall_10: 0.2406 - val_precision_10: 0.9627\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0887 - recall_10: 0.5553 - precision_10: 0.9998\n",
      "Epoch 27: loss did not improve from 0.08765\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0887 - recall_10: 0.5553 - precision_10: 0.9998 - val_loss: 0.2394 - val_recall_10: 0.2467 - val_precision_10: 0.9598\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0863 - recall_10: 0.5630 - precision_10: 0.9999\n",
      "Epoch 28: loss improved from 0.08765 to 0.08633, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0863 - recall_10: 0.5630 - precision_10: 0.9999 - val_loss: 0.2426 - val_recall_10: 0.2510 - val_precision_10: 0.9475\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0865 - recall_10: 0.5580 - precision_10: 0.9999\n",
      "Epoch 29: loss did not improve from 0.08633\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.0865 - recall_10: 0.5580 - precision_10: 0.9999 - val_loss: 0.2344 - val_recall_10: 0.2627 - val_precision_10: 0.9252\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0869 - recall_10: 0.5652 - precision_10: 0.9999\n",
      "Epoch 30: loss did not improve from 0.08633\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0869 - recall_10: 0.5652 - precision_10: 0.9999 - val_loss: 0.2252 - val_recall_10: 0.2656 - val_precision_10: 0.9445\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0860 - recall_10: 0.5697 - precision_10: 0.9999\n",
      "Epoch 31: loss improved from 0.08633 to 0.08599, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0860 - recall_10: 0.5697 - precision_10: 0.9999 - val_loss: 0.2191 - val_recall_10: 0.2682 - val_precision_10: 0.9680\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0847 - recall_10: 0.5562 - precision_10: 0.9999\n",
      "Epoch 32: loss improved from 0.08599 to 0.08470, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0847 - recall_10: 0.5562 - precision_10: 0.9999 - val_loss: 0.2209 - val_recall_10: 0.2639 - val_precision_10: 0.9748\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0830 - recall_10: 0.5627 - precision_10: 1.0000\n",
      "Epoch 33: loss improved from 0.08470 to 0.08300, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 58s 9s/step - loss: 0.0830 - recall_10: 0.5627 - precision_10: 1.0000 - val_loss: 0.2172 - val_recall_10: 0.2829 - val_precision_10: 0.9597\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0840 - recall_10: 0.5617 - precision_10: 1.0000\n",
      "Epoch 34: loss did not improve from 0.08300\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.0840 - recall_10: 0.5617 - precision_10: 1.0000 - val_loss: 0.2098 - val_recall_10: 0.2900 - val_precision_10: 0.9490\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0833 - recall_10: 0.5715 - precision_10: 1.0000\n",
      "Epoch 35: loss did not improve from 0.08300\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.0833 - recall_10: 0.5715 - precision_10: 1.0000 - val_loss: 0.1970 - val_recall_10: 0.2994 - val_precision_10: 0.9341\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0831 - recall_10: 0.5570 - precision_10: 0.9998\n",
      "Epoch 36: loss did not improve from 0.08300\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0831 - recall_10: 0.5570 - precision_10: 0.9998 - val_loss: 0.1975 - val_recall_10: 0.3074 - val_precision_10: 0.9269\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0824 - recall_10: 0.5535 - precision_10: 0.9999\n",
      "Epoch 37: loss improved from 0.08300 to 0.08239, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0824 - recall_10: 0.5535 - precision_10: 0.9999 - val_loss: 0.1981 - val_recall_10: 0.2994 - val_precision_10: 0.9554\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0832 - recall_10: 0.5725 - precision_10: 0.9999\n",
      "Epoch 38: loss did not improve from 0.08239\n",
      "7/7 [==============================] - 58s 9s/step - loss: 0.0832 - recall_10: 0.5725 - precision_10: 0.9999 - val_loss: 0.1991 - val_recall_10: 0.2932 - val_precision_10: 0.9697\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0808 - recall_10: 0.5620 - precision_10: 0.9999\n",
      "Epoch 39: loss improved from 0.08239 to 0.08085, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0808 - recall_10: 0.5620 - precision_10: 0.9999 - val_loss: 0.1965 - val_recall_10: 0.3100 - val_precision_10: 0.9550\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0798 - recall_10: 0.5555 - precision_10: 1.0000\n",
      "Epoch 40: loss improved from 0.08085 to 0.07975, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0798 - recall_10: 0.5555 - precision_10: 1.0000 - val_loss: 0.1966 - val_recall_10: 0.3197 - val_precision_10: 0.9428\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0784 - recall_10: 0.5612 - precision_10: 1.0000\n",
      "Epoch 41: loss improved from 0.07975 to 0.07836, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.0784 - recall_10: 0.5612 - precision_10: 1.0000 - val_loss: 0.1942 - val_recall_10: 0.3265 - val_precision_10: 0.9386\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0787 - recall_10: 0.5790 - precision_10: 1.0000\n",
      "Epoch 42: loss did not improve from 0.07836\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0787 - recall_10: 0.5790 - precision_10: 1.0000 - val_loss: 0.1910 - val_recall_10: 0.3336 - val_precision_10: 0.9437\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0762 - recall_10: 0.5694 - precision_10: 1.0000\n",
      "Epoch 43: loss improved from 0.07836 to 0.07618, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0762 - recall_10: 0.5694 - precision_10: 1.0000 - val_loss: 0.1891 - val_recall_10: 0.3422 - val_precision_10: 0.9384\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0759 - recall_10: 0.5634 - precision_10: 1.0000\n",
      "Epoch 44: loss improved from 0.07618 to 0.07587, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0759 - recall_10: 0.5634 - precision_10: 1.0000 - val_loss: 0.1885 - val_recall_10: 0.3468 - val_precision_10: 0.9377\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0750 - recall_10: 0.5702 - precision_10: 1.0000\n",
      "Epoch 45: loss improved from 0.07587 to 0.07500, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0750 - recall_10: 0.5702 - precision_10: 1.0000 - val_loss: 0.1871 - val_recall_10: 0.3506 - val_precision_10: 0.9375\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0753 - recall_10: 0.5706 - precision_10: 1.0000\n",
      "Epoch 46: loss did not improve from 0.07500\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.0753 - recall_10: 0.5706 - precision_10: 1.0000 - val_loss: 0.1870 - val_recall_10: 0.3558 - val_precision_10: 0.9316\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0750 - recall_10: 0.5746 - precision_10: 1.0000\n",
      "Epoch 47: loss improved from 0.07500 to 0.07499, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0750 - recall_10: 0.5746 - precision_10: 1.0000 - val_loss: 0.1866 - val_recall_10: 0.3632 - val_precision_10: 0.9217\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0738 - recall_10: 0.5631 - precision_10: 1.0000\n",
      "Epoch 48: loss improved from 0.07499 to 0.07383, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 64s 10s/step - loss: 0.0738 - recall_10: 0.5631 - precision_10: 1.0000 - val_loss: 0.1874 - val_recall_10: 0.3677 - val_precision_10: 0.9192\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0731 - recall_10: 0.5714 - precision_10: 1.0000\n",
      "Epoch 49: loss improved from 0.07383 to 0.07315, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0731 - recall_10: 0.5714 - precision_10: 1.0000 - val_loss: 0.1864 - val_recall_10: 0.3674 - val_precision_10: 0.9241\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0737 - recall_10: 0.5704 - precision_10: 1.0000\n",
      "Epoch 50: loss did not improve from 0.07315\n",
      "7/7 [==============================] - 58s 9s/step - loss: 0.0737 - recall_10: 0.5704 - precision_10: 1.0000 - val_loss: 0.1838 - val_recall_10: 0.3610 - val_precision_10: 0.9398\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0735 - recall_10: 0.5751 - precision_10: 1.0000\n",
      "Epoch 51: loss did not improve from 0.07315\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.0735 - recall_10: 0.5751 - precision_10: 1.0000 - val_loss: 0.1830 - val_recall_10: 0.3663 - val_precision_10: 0.9354\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0723 - recall_10: 0.5631 - precision_10: 1.0000\n",
      "Epoch 52: loss improved from 0.07315 to 0.07225, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0723 - recall_10: 0.5631 - precision_10: 1.0000 - val_loss: 0.1831 - val_recall_10: 0.3686 - val_precision_10: 0.9334\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0719 - recall_10: 0.5643 - precision_10: 1.0000\n",
      "Epoch 53: loss improved from 0.07225 to 0.07193, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0719 - recall_10: 0.5643 - precision_10: 1.0000 - val_loss: 0.1823 - val_recall_10: 0.3688 - val_precision_10: 0.9368\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0727 - recall_10: 0.5782 - precision_10: 1.0000\n",
      "Epoch 54: loss did not improve from 0.07193\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0727 - recall_10: 0.5782 - precision_10: 1.0000 - val_loss: 0.1869 - val_recall_10: 0.3839 - val_precision_10: 0.8987\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0730 - recall_10: 0.5670 - precision_10: 1.0000 \n",
      "Epoch 55: loss did not improve from 0.07193\n",
      "7/7 [==============================] - 104s 16s/step - loss: 0.0730 - recall_10: 0.5670 - precision_10: 1.0000 - val_loss: 0.1920 - val_recall_10: 0.3902 - val_precision_10: 0.8710\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0735 - recall_10: 0.5562 - precision_10: 1.0000\n",
      "Epoch 56: loss did not improve from 0.07193\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0735 - recall_10: 0.5562 - precision_10: 1.0000 - val_loss: 0.1837 - val_recall_10: 0.3797 - val_precision_10: 0.9118\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0736 - recall_10: 0.5591 - precision_10: 1.0000\n",
      "Epoch 57: loss did not improve from 0.07193\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0736 - recall_10: 0.5591 - precision_10: 1.0000 - val_loss: 0.1806 - val_recall_10: 0.3746 - val_precision_10: 0.9328\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0731 - recall_10: 0.5648 - precision_10: 1.0000\n",
      "Epoch 58: loss did not improve from 0.07193\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0731 - recall_10: 0.5648 - precision_10: 1.0000 - val_loss: 0.1805 - val_recall_10: 0.3806 - val_precision_10: 0.9258\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0724 - recall_10: 0.5788 - precision_10: 1.0000\n",
      "Epoch 59: loss did not improve from 0.07193\n",
      "7/7 [==============================] - 58s 9s/step - loss: 0.0724 - recall_10: 0.5788 - precision_10: 1.0000 - val_loss: 0.1799 - val_recall_10: 0.3851 - val_precision_10: 0.9268\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0711 - recall_10: 0.5604 - precision_10: 1.0000\n",
      "Epoch 60: loss improved from 0.07193 to 0.07108, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0711 - recall_10: 0.5604 - precision_10: 1.0000 - val_loss: 0.1800 - val_recall_10: 0.3843 - val_precision_10: 0.9270\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0702 - recall_10: 0.5621 - precision_10: 1.0000\n",
      "Epoch 61: loss improved from 0.07108 to 0.07021, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 102s 16s/step - loss: 0.0702 - recall_10: 0.5621 - precision_10: 1.0000 - val_loss: 0.1806 - val_recall_10: 0.3907 - val_precision_10: 0.9211\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0712 - recall_10: 0.5790 - precision_10: 1.0000\n",
      "Epoch 62: loss did not improve from 0.07021\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0712 - recall_10: 0.5790 - precision_10: 1.0000 - val_loss: 0.1816 - val_recall_10: 0.3950 - val_precision_10: 0.9134\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0683 - recall_10: 0.5654 - precision_10: 1.0000\n",
      "Epoch 63: loss improved from 0.07021 to 0.06835, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0683 - recall_10: 0.5654 - precision_10: 1.0000 - val_loss: 0.1824 - val_recall_10: 0.3938 - val_precision_10: 0.9107\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0695 - recall_10: 0.5723 - precision_10: 1.0000\n",
      "Epoch 64: loss did not improve from 0.06835\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0695 - recall_10: 0.5723 - precision_10: 1.0000 - val_loss: 0.1824 - val_recall_10: 0.3964 - val_precision_10: 0.9095\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0685 - recall_10: 0.5694 - precision_10: 1.0000\n",
      "Epoch 65: loss did not improve from 0.06835\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0685 - recall_10: 0.5694 - precision_10: 1.0000 - val_loss: 0.1796 - val_recall_10: 0.3915 - val_precision_10: 0.9241\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0695 - recall_10: 0.5700 - precision_10: 1.0000\n",
      "Epoch 66: loss did not improve from 0.06835\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0695 - recall_10: 0.5700 - precision_10: 1.0000 - val_loss: 0.1784 - val_recall_10: 0.3842 - val_precision_10: 0.9331\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0690 - recall_10: 0.5640 - precision_10: 1.0000\n",
      "Epoch 67: loss did not improve from 0.06835\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0690 - recall_10: 0.5640 - precision_10: 1.0000 - val_loss: 0.1795 - val_recall_10: 0.3834 - val_precision_10: 0.9317\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0691 - recall_10: 0.5700 - precision_10: 1.0000 \n",
      "Epoch 68: loss did not improve from 0.06835\n",
      "7/7 [==============================] - 101s 16s/step - loss: 0.0691 - recall_10: 0.5700 - precision_10: 1.0000 - val_loss: 0.1796 - val_recall_10: 0.3756 - val_precision_10: 0.9383\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0681 - recall_10: 0.5635 - precision_10: 1.0000\n",
      "Epoch 69: loss improved from 0.06835 to 0.06806, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.0681 - recall_10: 0.5635 - precision_10: 1.0000 - val_loss: 0.1801 - val_recall_10: 0.3925 - val_precision_10: 0.9199\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0688 - recall_10: 0.5698 - precision_10: 1.0000\n",
      "Epoch 70: loss did not improve from 0.06806\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0688 - recall_10: 0.5698 - precision_10: 1.0000 - val_loss: 0.1793 - val_recall_10: 0.3992 - val_precision_10: 0.9181\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0687 - recall_10: 0.5661 - precision_10: 1.0000\n",
      "Epoch 71: loss did not improve from 0.06806\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.0687 - recall_10: 0.5661 - precision_10: 1.0000 - val_loss: 0.1806 - val_recall_10: 0.4002 - val_precision_10: 0.9096\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0674 - recall_10: 0.5679 - precision_10: 1.0000\n",
      "Epoch 72: loss improved from 0.06806 to 0.06742, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0674 - recall_10: 0.5679 - precision_10: 1.0000 - val_loss: 0.1816 - val_recall_10: 0.3975 - val_precision_10: 0.9084\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0683 - recall_10: 0.5715 - precision_10: 1.0000\n",
      "Epoch 73: loss did not improve from 0.06742\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0683 - recall_10: 0.5715 - precision_10: 1.0000 - val_loss: 0.1798 - val_recall_10: 0.3814 - val_precision_10: 0.9286\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0674 - recall_10: 0.5597 - precision_10: 1.0000\n",
      "Epoch 74: loss improved from 0.06742 to 0.06740, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.0674 - recall_10: 0.5597 - precision_10: 1.0000 - val_loss: 0.1786 - val_recall_10: 0.3867 - val_precision_10: 0.9291\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0672 - recall_10: 0.5738 - precision_10: 1.0000\n",
      "Epoch 75: loss improved from 0.06740 to 0.06718, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0672 - recall_10: 0.5738 - precision_10: 1.0000 - val_loss: 0.1797 - val_recall_10: 0.3948 - val_precision_10: 0.9203\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0674 - recall_10: 0.5692 - precision_10: 1.0000\n",
      "Epoch 76: loss did not improve from 0.06718\n",
      "7/7 [==============================] - 62s 9s/step - loss: 0.0674 - recall_10: 0.5692 - precision_10: 1.0000 - val_loss: 0.1823 - val_recall_10: 0.4048 - val_precision_10: 0.9042\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0673 - recall_10: 0.5743 - precision_10: 1.0000\n",
      "Epoch 77: loss did not improve from 0.06718\n",
      "7/7 [==============================] - 64s 9s/step - loss: 0.0673 - recall_10: 0.5743 - precision_10: 1.0000 - val_loss: 0.1791 - val_recall_10: 0.3921 - val_precision_10: 0.9248\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0667 - recall_10: 0.5602 - precision_10: 1.0000\n",
      "Epoch 78: loss improved from 0.06718 to 0.06674, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.0667 - recall_10: 0.5602 - precision_10: 1.0000 - val_loss: 0.1787 - val_recall_10: 0.3963 - val_precision_10: 0.9239\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0669 - recall_10: 0.5627 - precision_10: 1.0000\n",
      "Epoch 79: loss did not improve from 0.06674\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0669 - recall_10: 0.5627 - precision_10: 1.0000 - val_loss: 0.1798 - val_recall_10: 0.4039 - val_precision_10: 0.9140\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0671 - recall_10: 0.5668 - precision_10: 1.0000\n",
      "Epoch 80: loss did not improve from 0.06674\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0671 - recall_10: 0.5668 - precision_10: 1.0000 - val_loss: 0.1784 - val_recall_10: 0.3915 - val_precision_10: 0.9315\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0671 - recall_10: 0.5726 - precision_10: 1.0000\n",
      "Epoch 81: loss did not improve from 0.06674\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0671 - recall_10: 0.5726 - precision_10: 1.0000 - val_loss: 0.1821 - val_recall_10: 0.4081 - val_precision_10: 0.9037\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0658 - recall_10: 0.5623 - precision_10: 1.0000\n",
      "Epoch 82: loss improved from 0.06674 to 0.06576, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 87s 13s/step - loss: 0.0658 - recall_10: 0.5623 - precision_10: 1.0000 - val_loss: 0.1826 - val_recall_10: 0.4081 - val_precision_10: 0.9025\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0647 - recall_10: 0.5643 - precision_10: 1.0000\n",
      "Epoch 83: loss improved from 0.06576 to 0.06468, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 77s 9s/step - loss: 0.0647 - recall_10: 0.5643 - precision_10: 1.0000 - val_loss: 0.1868 - val_recall_10: 0.4142 - val_precision_10: 0.8903\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0662 - recall_10: 0.5737 - precision_10: 1.0000\n",
      "Epoch 84: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0662 - recall_10: 0.5737 - precision_10: 1.0000 - val_loss: 0.1849 - val_recall_10: 0.4107 - val_precision_10: 0.9007\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0648 - recall_10: 0.5680 - precision_10: 1.0000\n",
      "Epoch 85: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 59s 8s/step - loss: 0.0648 - recall_10: 0.5680 - precision_10: 1.0000 - val_loss: 0.1851 - val_recall_10: 0.4122 - val_precision_10: 0.8966\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0651 - recall_10: 0.5601 - precision_10: 1.0000\n",
      "Epoch 86: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0651 - recall_10: 0.5601 - precision_10: 1.0000 - val_loss: 0.1788 - val_recall_10: 0.3973 - val_precision_10: 0.9235\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0669 - recall_10: 0.5672 - precision_10: 1.0000\n",
      "Epoch 87: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0669 - recall_10: 0.5672 - precision_10: 1.0000 - val_loss: 0.1793 - val_recall_10: 0.4038 - val_precision_10: 0.9176\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0667 - recall_10: 0.5732 - precision_10: 1.0000\n",
      "Epoch 88: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0667 - recall_10: 0.5732 - precision_10: 1.0000 - val_loss: 0.1792 - val_recall_10: 0.4091 - val_precision_10: 0.9129\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0659 - recall_10: 0.5645 - precision_10: 1.0000 \n",
      "Epoch 89: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 102s 16s/step - loss: 0.0659 - recall_10: 0.5645 - precision_10: 1.0000 - val_loss: 0.1862 - val_recall_10: 0.4203 - val_precision_10: 0.8822\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0669 - recall_10: 0.5715 - precision_10: 1.0000\n",
      "Epoch 90: loss did not improve from 0.06468\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.0669 - recall_10: 0.5715 - precision_10: 1.0000 - val_loss: 0.1824 - val_recall_10: 0.4167 - val_precision_10: 0.9042\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0642 - recall_10: 0.5606 - precision_10: 1.0000\n",
      "Epoch 91: loss improved from 0.06468 to 0.06418, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0642 - recall_10: 0.5606 - precision_10: 1.0000 - val_loss: 0.1822 - val_recall_10: 0.4138 - val_precision_10: 0.9081\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0636 - recall_10: 0.5644 - precision_10: 1.0000\n",
      "Epoch 92: loss improved from 0.06418 to 0.06357, saving model to unet_eye4.hdf5\n",
      "7/7 [==============================] - 60s 9s/step - loss: 0.0636 - recall_10: 0.5644 - precision_10: 1.0000 - val_loss: 0.1834 - val_recall_10: 0.4211 - val_precision_10: 0.8990\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0639 - recall_10: 0.5633 - precision_10: 1.0000\n",
      "Epoch 93: loss did not improve from 0.06357\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0639 - recall_10: 0.5633 - precision_10: 1.0000 - val_loss: 0.1873 - val_recall_10: 0.4264 - val_precision_10: 0.8778\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0647 - recall_10: 0.5837 - precision_10: 1.0000\n",
      "Epoch 94: loss did not improve from 0.06357\n",
      "7/7 [==============================] - 59s 9s/step - loss: 0.0647 - recall_10: 0.5837 - precision_10: 1.0000 - val_loss: 0.1831 - val_recall_10: 0.4087 - val_precision_10: 0.9039\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0639 - recall_10: 0.5694 - precision_10: 1.0000 \n",
      "Epoch 95: loss did not improve from 0.06357\n",
      "7/7 [==============================] - 106s 16s/step - loss: 0.0639 - recall_10: 0.5694 - precision_10: 1.0000 - val_loss: 0.1823 - val_recall_10: 0.4136 - val_precision_10: 0.9077\n",
      "18/18 [==============================] - 33s 2s/step\n",
      "\n",
      "Accuracy: 0.9211807250976562\n",
      "Recall: 1.0\n",
      "Precision: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model()\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}